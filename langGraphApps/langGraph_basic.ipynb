{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f2f1309a-7072-45fd-b4a9-518ef492b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "mistral_api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "tavily_api_key = os.environ[\"TAVILY_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ebe0a9-00fa-4025-bbd9-7c3e1a2927c2",
   "metadata": {},
   "source": [
    "## Step by step break down\n",
    "\n",
    "* Initialize the model and tools\n",
    "* Initialize graph with state\n",
    "* Define graph nodes\n",
    "* Define entry point and graph edges\n",
    "* Compile the graph\n",
    "* Execute the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528f21b-9314-4924-a113-f76b56e2be4c",
   "metadata": {},
   "source": [
    "## Initialize Mistral LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fea9452-2440-42f7-b48a-284708f827f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "llm = ChatMistralAI(\n",
    "    mistral_api_key=mistral_api_key,\n",
    "    model=\"mistral-large-latest\",\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346e1240-8fe2-47ca-b4e6-ceff5fc2dfdb",
   "metadata": {},
   "source": [
    "## Initialize Lang Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "844acede-aa88-456d-b60d-e438587b1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, MessageGraph\n",
    "agent = MessageGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4edda1a-5c47-46e0-8dfe-048d886bf926",
   "metadata": {},
   "source": [
    "### Define and add nodes in graph.\n",
    "\n",
    "* Next, we add a single node to the agent, called \"node1\", which simply calls the LLM with the given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20986578-cdfc-4037-a81a-c0a2e02437ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x1053c2b10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.add_node(\"node1\", llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5a201-8c68-4134-9014-57c5bc02c225",
   "metadata": {},
   "source": [
    "### Add edge\n",
    "* We add an edge from this \"node1\" node to the special string END (__end__). This means that execution will end after the current node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d12f00d8-4b1b-477f-bebc-bf0e5a439bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x1053c2b10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.add_edge(\"node1\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df80455-0e92-4ead-861b-2be83f712840",
   "metadata": {},
   "source": [
    "## Set Entry point\n",
    "* Set \"node1\" as the entry point to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c96eb0d-4138-404b-9c91-1b950a6f89c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x1053c2b10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.set_entry_point(\"node1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb5ea2-ce7f-4f8b-af6a-8a479f976048",
   "metadata": {},
   "source": [
    "## Compile\n",
    "* We compile the agent, translating it to low-level pregel operations ensuring that it can be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "973255e4-e8ca-4102-81b4-9924c4cb8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable_agent = agent.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7edc6-75f9-49cf-b621-0853939c52f9",
   "metadata": {},
   "source": [
    "## Execute the agent\n",
    "\n",
    "When we execute the agent:\n",
    "\n",
    "    LangGraph adds the input message to the state, then passes the state to the entrypoint node, \"node1\".\n",
    "    The \"node1\" node executes, invoking the chat model.\n",
    "    The chat model returns an AIMessage. LangGraph adds this to the state.\n",
    "    Execution progresses to the special END value and outputs the final state.\n",
    "    And as a result, we get a list of two chat messages as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b616921-2e97-466e-b789-d824af3823ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 1+1 ?', additional_kwargs={}, response_metadata={}, id='c3ee7787-78ed-419b-aab0-ca0b8d1851c6'),\n",
       " AIMessage(content='The sum of 1 + 1 is 2. Here it is:\\n\\n 1\\n+1\\n____\\n 2', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 10, 'total_tokens': 38, 'completion_tokens': 28}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-d3a0fee0-5c26-44a7-95cc-e8c9175e70d5-0', usage_metadata={'input_tokens': 10, 'output_tokens': 28, 'total_tokens': 38})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "runnable_agent.invoke(HumanMessage(\"What is 1+1 ?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91177c2-cefd-4560-96d6-bc407a2bd364",
   "metadata": {},
   "source": [
    "## Agent with a router and conditional edges\n",
    "\n",
    "    Let's allow the LLM to conditionally call a \"multiply\" node using tool calling.\n",
    "    We'll recreate our previous agent with an additional \"multiply\" tool that will take the result of the most recent message, if it is a tool call, and calculate the result.\n",
    "    We will bind the multiply tool to the OpenAI model to allow the llm to optionally use the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6da33e3f-f7fd-46a8-bf25-df7639a0058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write a tool\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "@tool\n",
    "def multiply (first: int, sec: int):\n",
    "    \"\"\"Multiplies two numbers together\"\"\"\n",
    "    return first*sec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5bbc5443-22f0-4e86-b316-f24c9c0ade9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create llm and bind multiply tool\n",
    "llm = ChatMistralAI(\n",
    "    mistral_api_key=mistral_api_key,\n",
    "    model=\"mistral-large-latest\",\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cafe4f8e-076e-4021-8e60-ce8615ab9868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x105f0f810>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create an agent\n",
    "conditional_agent = MessageGraph()\n",
    "\n",
    "# Create first node and set it as entry point\n",
    "conditional_agent.add_node(\"node1\", llm_with_tools)\n",
    "conditional_agent.set_entry_point(\"node1\")\n",
    "\n",
    "# Create second node\n",
    "tool_node = ToolNode([multiply])\n",
    "conditional_agent.add_node(\"multiply\", tool_node)\n",
    "\n",
    "# Create edge \n",
    "conditional_agent.add_edge(\"multiply\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eee8a9-10ed-40df-90cb-c2a4228f8963",
   "metadata": {},
   "source": [
    "## Conditional Router\n",
    "\n",
    "Using conditional edges, which call a function on the current state and routes execution to a node the function's output:\n",
    "* If the \"node1\" node returns a message expecting a tool call, we want to execute the \"multiply\" node.\n",
    "* If not, we can just end execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb081ad3-ffc1-4569-b206-32ad23679220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x105f0f810>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "def router(state: List[BaseMessage]) -> Literal[\"multiply\", \"__end__\"]:\n",
    "    tool_calls = state[-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    if len(tool_calls):\n",
    "        return \"multiply\"\n",
    "    else:\n",
    "        return \"__end__\"\n",
    "\n",
    "conditional_agent.add_conditional_edges(\"node1\", router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33ee3cc1-cb0a-439c-8e2a-d87e11514463",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable_conditional_agent = conditional_agent.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26515a71-1df9-4466-9f47-a7cf8eae0c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 123 * 456?', additional_kwargs={}, response_metadata={}, id='8d657aa5-6dd1-42b9-a2da-4bd9c9421075'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '7L6WrclW9', 'type': 'function', 'function': {'name': 'multiply', 'arguments': '{\"first\": 123, \"sec\": 456}'}}]}, response_metadata={'token_usage': {'prompt_tokens': 86, 'total_tokens': 115, 'completion_tokens': 29}, 'model': 'mistral-large-latest', 'finish_reason': 'tool_calls'}, id='run-fdb45afa-018d-4e3b-bd7c-b630a18757c8-0', tool_calls=[{'name': 'multiply', 'args': {'first': 123, 'sec': 456}, 'id': '7L6WrclW9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 86, 'output_tokens': 29, 'total_tokens': 115}),\n",
       " ToolMessage(content='56088', name='multiply', id='4907c941-8b80-4687-a21e-a6bb5094a82b', tool_call_id='7L6WrclW9')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_conditional_agent.invoke(HumanMessage(\"What is 123 * 456?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c62b4b6-d620-4bbe-b6f7-b9fed1dd32cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={}, id='b7a18e3d-182d-48e2-ae3c-7f6404b03836'),\n",
       " AIMessage(content='My name is Assistant.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 79, 'total_tokens': 84, 'completion_tokens': 5}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-b0c185c3-e3b8-4030-bd77-a2202e6b7376-0', usage_metadata={'input_tokens': 79, 'output_tokens': 5, 'total_tokens': 84})]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_conditional_agent.invoke(HumanMessage(\"What is your name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07457f38-3a51-4a0b-aa7f-0ecdde5505b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ad9c1a3-ee66-4a12-bfc6-23b38f98691d",
   "metadata": {},
   "source": [
    "## Agent With Cycle\n",
    "\n",
    "    We will use Tavily as online search tool"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2b9bbe7-4de1-4c90-90ec-e3ef5da000e9",
   "metadata": {},
   "source": [
    "TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4577cf9e-bde7-4625-adab-1f42e3d49128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "online_search_tool = [TavilySearchResults(tavily_api_key = tavily_api_key, max_results=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41871beb-06d2-4960-9d72-2db82c80f330",
   "metadata": {},
   "source": [
    "### \n",
    "now wrap these tools in a simple LangGraph ToolNode. This class receives the list of messages (containing tool_calls), calls the tool(s) the LLM has requested to run, and returns the output as new ToolMessage(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1f42fc4-0b53-44a1-91a3-8d46f8ac5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "online_search_tool_node = ToolNode(online_search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b33b3f29-ab4f-4cac-b975-cb87166ad7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create llm and bind tool\n",
    "llm = ChatMistralAI(\n",
    "    mistral_api_key=mistral_api_key,\n",
    "    model=\"mistral-large-latest\",\n",
    "    temperature=0,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(online_search_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f05193-63af-4c13-afe6-ae0fb72449c1",
   "metadata": {},
   "source": [
    " Let's now define the state of the agent.\n",
    "* Each node will return operations to update the state.\n",
    "* For this example, we want each node to just add messages to the state. Therefore, in this case the state of the agent will be a list of messages. In other projects, the state can be any type.\n",
    "* We will use a TypedDict with one key (messages) and annotate it so that we always add to the messages key when updating it using the `is always added to` with the second parameter (operator.add)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1410dbf8-4c8f-495e-b0b6-1298ec9aaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "\n",
    "def add_messages(left: list, right:list):\n",
    "    \"\"\"Add-don't-overwrite.\"\"\"\n",
    "    return left + right\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The `add_messages` function within the annotation defines\n",
    "    # *how* updates should be merged into the state.\n",
    "    messages:Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34664a00-a069-4aa6-a3f8-48b7c66ce246",
   "metadata": {},
   "source": [
    "## Router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186a176-d408-40c8-bb19-d197e4a1f7f0",
   "metadata": {},
   "source": [
    "* Let's now define the nodes of this agent:\n",
    "    * the node responsible for deciding what (if any) actions to take.\n",
    "    * if the previous node decides to take an action, this second node will then execute that action calling the online search tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ec107-23fa-4992-90a9-684a27a1ed2c",
   "metadata": {},
   "source": [
    "* We will also define the edges that will interconnect the nodes.\n",
    "* One will be a Conditional Edge. After the node1 is called, the llm will dedice either:\n",
    "    * a. Run the online search tool (node2), OR\n",
    "    * b. Finish\n",
    "\n",
    "* The second will be a normal Edge: after the online search tool (node2) is invoked, the graph should always return to the node1 to decide what to do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "95352292-8eed-4e5b-a556-30f1d9b52be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "## Router Function\n",
    "def should_continue(state: AgentState)->Literal[\"node2\", \"__end__\"]:\n",
    "    message = state['messages']\n",
    "    last_message = message[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"action\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"node2\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return \"__end__\"\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state:AgentState):\n",
    "    messages = state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b751f6aa-1b64-41b7-8268-6f5cb8b30f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1076ece10>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# define a new Graph\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"node1\", call_model)\n",
    "workflow.add_node(\"node2\", online_search_tool_node)\n",
    "\n",
    "# Set the entrypoint as `node1`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"node1\")\n",
    "\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `node1`.\n",
    "    # This means these are the edges taken after the `node1` node is called.\n",
    "    \"node1\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `online_search_tool` to `node1`.\n",
    "# This means that after `online_search_tool` is called, `node1` node is called next.\n",
    "workflow.add_edge('node2', 'node1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e0e97783-76ea-4124-af4f-e1d366c7f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_cycles = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a6090301-8f43-4e56-90be-c49683a95866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'k302hN2i4', 'type': 'function', 'function': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"weather in sf\"}'}}]}, response_metadata={'token_usage': {'prompt_tokens': 113, 'total_tokens': 143, 'completion_tokens': 30}, 'model': 'mistral-large-latest', 'finish_reason': 'tool_calls'}, id='run-7e9cc987-72ae-4142-affc-0eae7a2cbe57-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in sf'}, 'id': 'k302hN2i4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 113, 'output_tokens': 30, 'total_tokens': 143}),\n",
       "  ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1731396266, \\'localtime\\': \\'2024-11-11 23:24\\'}, \\'current\\': {\\'last_updated_epoch\\': 1731395700, \\'last_updated\\': \\'2024-11-11 23:15\\', \\'temp_c\\': 13.9, \\'temp_f\\': 57.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 9.4, \\'wind_kph\\': 15.1, \\'wind_degree\\': 288, \\'wind_dir\\': \\'WNW\\', \\'pressure_mb\\': 1022.0, \\'pressure_in\\': 30.17, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 83, \\'cloud\\': 25, \\'feelslike_c\\': 12.7, \\'feelslike_f\\': 54.9, \\'windchill_c\\': 11.1, \\'windchill_f\\': 52.0, \\'heatindex_c\\': 12.2, \\'heatindex_f\\': 54.0, \\'dewpoint_c\\': 8.3, \\'dewpoint_f\\': 47.0, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 15.0, \\'gust_kph\\': 24.2}}\"}]', name='tavily_search_results_json', tool_call_id='k302hN2i4', artifact={'query': 'weather in sf', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in San Francisco', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1731396266, 'localtime': '2024-11-11 23:24'}, 'current': {'last_updated_epoch': 1731395700, 'last_updated': '2024-11-11 23:15', 'temp_c': 13.9, 'temp_f': 57.0, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 9.4, 'wind_kph': 15.1, 'wind_degree': 288, 'wind_dir': 'WNW', 'pressure_mb': 1022.0, 'pressure_in': 30.17, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 83, 'cloud': 25, 'feelslike_c': 12.7, 'feelslike_f': 54.9, 'windchill_c': 11.1, 'windchill_f': 52.0, 'heatindex_c': 12.2, 'heatindex_f': 54.0, 'dewpoint_c': 8.3, 'dewpoint_f': 47.0, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 15.0, 'gust_kph': 24.2}}\", 'score': 0.9988062, 'raw_content': None}], 'response_time': 3.57}),\n",
       "  AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 57.0°F (13.9°C). The wind is blowing at 9.4 mph (15.1 km/h) from the west-northwest direction. The humidity is 83%, and the pressure is 1022.0 mb (30.17 in). There is no precipitation at the moment. The visibility is 16.0 km (9.0 miles), and the UV index is 0.0. The wind chill is 52.0°F (11.1°C), and the heat index is 54.0°F (12.2°C). The dew point is 47.0°F (8.3°C). The last update was at 2024-11-11 23:15.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 687, 'total_tokens': 888, 'completion_tokens': 201}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-ecef9fb1-44ed-4da6-aa10-a71de2f77140-0', usage_metadata={'input_tokens': 687, 'output_tokens': 201, 'total_tokens': 888})]}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
    "agent_with_cycles.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "60faf364-46e1-472a-8e86-61baa542864d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How about weather of Bangalore whitefield on Saturday, 16th Nov-2024', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'RGxXmBCcW', 'type': 'function', 'function': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"weather of Bangalore whitefield on Saturday, 16th Nov-2024\"}'}}]}, response_metadata={'token_usage': {'prompt_tokens': 129, 'total_tokens': 176, 'completion_tokens': 47}, 'model': 'mistral-large-latest', 'finish_reason': 'tool_calls'}, id='run-faef9c3e-f449-423c-842a-59c3fbd59e4f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather of Bangalore whitefield on Saturday, 16th Nov-2024'}, 'id': 'RGxXmBCcW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 129, 'output_tokens': 47, 'total_tokens': 176}),\n",
       "  ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'Bangalore\\', \\'region\\': \\'Karnataka\\', \\'country\\': \\'India\\', \\'lat\\': 12.9833, \\'lon\\': 77.5833, \\'tz_id\\': \\'Asia/Kolkata\\', \\'localtime_epoch\\': 1731398051, \\'localtime\\': \\'2024-11-12 13:24\\'}, \\'current\\': {\\'last_updated_epoch\\': 1731397500, \\'last_updated\\': \\'2024-11-12 13:15\\', \\'temp_c\\': 25.2, \\'temp_f\\': 77.4, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 7.8, \\'wind_kph\\': 12.6, \\'wind_degree\\': 30, \\'wind_dir\\': \\'NNE\\', \\'pressure_mb\\': 1015.0, \\'pressure_in\\': 29.97, \\'precip_mm\\': 0.17, \\'precip_in\\': 0.01, \\'humidity\\': 79, \\'cloud\\': 75, \\'feelslike_c\\': 27.0, \\'feelslike_f\\': 80.6, \\'windchill_c\\': 23.7, \\'windchill_f\\': 74.6, \\'heatindex_c\\': 25.5, \\'heatindex_f\\': 77.8, \\'dewpoint_c\\': 18.6, \\'dewpoint_f\\': 65.6, \\'vis_km\\': 3.0, \\'vis_miles\\': 1.0, \\'uv\\': 8.1, \\'gust_mph\\': 10.0, \\'gust_kph\\': 16.0}}\"}]', name='tavily_search_results_json', tool_call_id='RGxXmBCcW', artifact={'query': 'weather of Bangalore whitefield on Saturday, 16th Nov-2024', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in Bangalore Whitefield', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Bangalore', 'region': 'Karnataka', 'country': 'India', 'lat': 12.9833, 'lon': 77.5833, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1731398051, 'localtime': '2024-11-12 13:24'}, 'current': {'last_updated_epoch': 1731397500, 'last_updated': '2024-11-12 13:15', 'temp_c': 25.2, 'temp_f': 77.4, 'is_day': 1, 'condition': {'text': 'Mist', 'icon': '//cdn.weatherapi.com/weather/64x64/day/143.png', 'code': 1030}, 'wind_mph': 7.8, 'wind_kph': 12.6, 'wind_degree': 30, 'wind_dir': 'NNE', 'pressure_mb': 1015.0, 'pressure_in': 29.97, 'precip_mm': 0.17, 'precip_in': 0.01, 'humidity': 79, 'cloud': 75, 'feelslike_c': 27.0, 'feelslike_f': 80.6, 'windchill_c': 23.7, 'windchill_f': 74.6, 'heatindex_c': 25.5, 'heatindex_f': 77.8, 'dewpoint_c': 18.6, 'dewpoint_f': 65.6, 'vis_km': 3.0, 'vis_miles': 1.0, 'uv': 8.1, 'gust_mph': 10.0, 'gust_kph': 16.0}}\", 'score': 0.9475033, 'raw_content': None}], 'response_time': 3.18}),\n",
       "  AIMessage(content='The weather in Bangalore Whitefield on Saturday, 16th Nov-2024 is expected to be misty with a temperature of 25.2°C (77.4°F). The wind speed is 7.8 mph (12.6 km/h) from the NNE direction, and the humidity is 79%. The cloud cover is 75%, and the UV index is 8.1. The feels-like temperature is 27.0°C (80.6°F).', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 718, 'total_tokens': 837, 'completion_tokens': 119}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-29933d44-d91b-4ba2-84e9-04bc23e10d4d-0', usage_metadata={'input_tokens': 718, 'output_tokens': 119, 'total_tokens': 837})]}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\"How about weather of Bangalore whitefield on Saturday, 16th Nov-2024\")]}\n",
    "agent_with_cycles.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e8719c43-96cf-45f6-8963-703ea3c8f289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=' According to Vastu, In which direction should cook face while cokkking? Kitech is in south east direction', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8jQERu0L0', 'type': 'function', 'function': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"According to Vastu, In which direction should cook face while cokkking? Kitech is in south east direction\"}'}}]}, response_metadata={'token_usage': {'prompt_tokens': 134, 'total_tokens': 187, 'completion_tokens': 53}, 'model': 'mistral-large-latest', 'finish_reason': 'tool_calls'}, id='run-3366f0c5-9df2-488e-8d1f-c9985f3db351-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'According to Vastu, In which direction should cook face while cokkking? Kitech is in south east direction'}, 'id': '8jQERu0L0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 134, 'output_tokens': 53, 'total_tokens': 187}),\n",
       "  ToolMessage(content='[{\"url\": \"https://vastushala.com/403-direction-face-while-cooking-vastu/\", \"content\": \"Best Direction for Kitchen in the House. The South-East direction is called the \\\\\"Agni\\\\\" Disha. And in any kitchen, the most essential factor is fire. As per Vaastu Shastra, the element Fire governs in the direction South-East and so this directions of the house is best for kitchen. However, if South-East direction isn\\'t possible, one can\"}]', name='tavily_search_results_json', tool_call_id='8jQERu0L0', artifact={'query': 'According to Vastu, In which direction should cook face while cokkking? Kitech is in south east direction', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Direction of Face While Cooking as per Vastu - Vastu Shala', 'url': 'https://vastushala.com/403-direction-face-while-cooking-vastu/', 'content': 'Best Direction for Kitchen in the House. The South-East direction is called the \"Agni\" Disha. And in any kitchen, the most essential factor is fire. As per Vaastu Shastra, the element Fire governs in the direction South-East and so this directions of the house is best for kitchen. However, if South-East direction isn\\'t possible, one can', 'score': 0.99459416, 'raw_content': None}], 'response_time': 3.54}),\n",
       "  AIMessage(content='According to Vastu Shastra, the South-East direction is called the \"Agni\" Disha, and it is considered the best direction for the kitchen in the house. The element Fire governs in the South-East direction, making it ideal for cooking activities. If the South-East direction is not possible, other directions can be considered, but South-East is the most favorable.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 335, 'total_tokens': 422, 'completion_tokens': 87}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-cae89f55-93de-4ace-8e11-6b52d003b9d6-0', usage_metadata={'input_tokens': 335, 'output_tokens': 87, 'total_tokens': 422})]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\" According to Vastu, In which direction should cook face while cokkking? Kitech is in south east direction\")]}\n",
    "agent_with_cycles.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c5c45b27-f493-48db-8d78-c4054c888383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\" According to Vastu, In which direction should cook face while cokkking? What is the mitigation plan if cook will not able to face vastu's suggested direction\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'p5TgFbkBG', 'type': 'function', 'function': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"According to Vastu, In which direction should cook face while cokkking? What is the mitigation plan if cook will not able to face vastu\\'s suggested direction\"}'}}]}, response_metadata={'token_usage': {'prompt_tokens': 145, 'total_tokens': 209, 'completion_tokens': 64}, 'model': 'mistral-large-latest', 'finish_reason': 'tool_calls'}, id='run-30551ca8-2956-4724-bdf9-b2552af97fa3-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': \"According to Vastu, In which direction should cook face while cokkking? What is the mitigation plan if cook will not able to face vastu's suggested direction\"}, 'id': 'p5TgFbkBG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 145, 'output_tokens': 64, 'total_tokens': 209}),\n",
       "  ToolMessage(content='[{\"url\": \"https://acharyaganesh.com/vastu/west-facing-house-vastu/\", \"content\": \"Principles of West Facing House Vastu. West Facing House Vastu is based on several fundamental principles that govern the flow of energy within a home. Here are the key concepts to keep in mind: 1. Sun\\'s movement: The west direction is associated with the setting sun, symbolizing the end of the day and new beginnings. This makes west facing\"}]', name='tavily_search_results_json', tool_call_id='p5TgFbkBG', artifact={'query': \"According to Vastu, In which direction should cook face while cokkking? What is the mitigation plan if cook will not able to face vastu's suggested direction\", 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'West Facing House Vastu: Ultimate Guide for Harmony', 'url': 'https://acharyaganesh.com/vastu/west-facing-house-vastu/', 'content': \"Principles of West Facing House Vastu. West Facing House Vastu is based on several fundamental principles that govern the flow of energy within a home. Here are the key concepts to keep in mind: 1. Sun's movement: The west direction is associated with the setting sun, symbolizing the end of the day and new beginnings. This makes west facing\", 'score': 0.98576, 'raw_content': None}], 'response_time': 4.77}),\n",
       "  AIMessage(content='According to Vastu, the cook should ideally face the east direction while cooking. This is because the east is associated with the rising sun and positive energy, which is believed to enhance the quality and taste of the food.\\n\\nIf the cook is unable to face the east direction, there are a few mitigation plans that can be implemented:\\n\\n1. **Use of Mirrors**: Place a mirror on the wall opposite the cooking area so that the cook can see the reflection of the east direction while cooking. This is believed to help in balancing the energy.\\n\\n2. **Color Therapy**: Use colors that are associated with the east direction, such as green or light blue, in the kitchen. These colors can help in creating a positive and harmonious environment.\\n\\n3. **Placement of Stove**: If possible, adjust the placement of the stove so that it is in the southeast corner of the kitchen. This is considered the ideal location for the fire element, which is associated with cooking.\\n\\n4. **Use of Crystals**: Place crystals or other Vastu remedies in the kitchen to help in balancing the energy. For example, a pyramid made of copper or brass can be placed in the southeast corner of the kitchen.\\n\\n5. **Prayers and Mantras**: Recite prayers or mantras while cooking to invoke positive energy and blessings. This can help in creating a sacred and peaceful atmosphere in the kitchen.\\n\\nBy implementing these mitigation plans, it is believed that the negative effects of not facing the east direction while cooking can be minimized. However, it is always best to consult with a Vastu expert for personalized advice and guidance.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 350, 'total_tokens': 709, 'completion_tokens': 359}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run-caa98b9b-63be-4cef-9b83-2a9841d702ed-0', usage_metadata={'input_tokens': 350, 'output_tokens': 359, 'total_tokens': 709})]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\" According to Vastu, In which direction should cook face while cokkking? What is the mitigation plan if cook will not able to face vastu's suggested direction\")]}\n",
    "agent_with_cycles.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1560cf21-aeb7-457f-b6b8-5edf81c5027a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-env-langgraph",
   "language": "python",
   "name": "poetry-env-langgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
