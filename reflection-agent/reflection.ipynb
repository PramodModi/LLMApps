{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b568418e-cdb8-4331-a243-892f0c22c28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramodmodi/Library/Caches/pypoetry/virtualenvs/reflection-agent-J-iJ8P-G-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18b65041-8e15-40e4-a4e8-ec148699b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "mistral_api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "google_api_key = os.environ[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f72fe3f-7a5d-46fb-8e2b-4d6ba26fcb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatMistralAI(\n",
    "#     mistral_api_key=mistral_api_key,\n",
    "#     model=\"mistral-large-latest\",\n",
    "#     temperature=0,\n",
    "#     max_retries=2,\n",
    "#     # other params...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fed579ee-c528-4415-bd75-c568736cbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9dc3f19e-7cd1-40ef-8a54-4a7b9931c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a viral twitter influencer grading a tweet. Generate critique and recommendations for the user's tweet.\"\n",
    "            \"Always provide detailed recommendations, including requests for length, virality, style, etc.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a twitter techie influencer assistant tasked with writing excellent twitter posts.\"\n",
    "            \" Generate the best twitter post possible for the user's request.\"\n",
    "            \" If the user provides critique, respond with a revised version of your previous attempts.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d41a4260-b321-4f3f-937a-14593547f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_chain = generation_prompt | llm\n",
    "reflect_chain = reflection_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c809396-c67b-42fa-8c98-2676fb9847b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from typing import List, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd45e85-4a7e-4768-8dd7-1eb6e51b4735",
   "metadata": {},
   "source": [
    "## Two nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8094e46c-367a-4fd6-9c9e-70f9b8c45e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "REFLECT = \"reflect\"\n",
    "GENERATE = \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d86eff82-26bd-4b45-aca7-d0c8ca0bbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: Sequence[BaseMessage]):\n",
    "    #res = generate_chain.invoke({\"messages\": state})\n",
    "    #return [res.content]\n",
    "   # return [AIMessage(content=generate_chain.invoke({\"messages\": state}))]\n",
    "    return generate_chain.invoke({\"messages\": state})\n",
    "\n",
    "\n",
    "def reflection_node(messages: Sequence[BaseMessage]) -> List[BaseMessage]:\n",
    "    res = reflect_chain.invoke({\"messages\": messages})\n",
    "    return [HumanMessage(content=res.content)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced65ca-48cc-4a8b-ad64-c3ecaddba0d1",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "745a6ad0-c555-41a5-a7d9-e01f767da752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x10cc1b450>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "builder = MessageGraph()\n",
    "builder.add_node(GENERATE, generation_node)\n",
    "builder.add_node(REFLECT, reflection_node)\n",
    "builder.set_entry_point(GENERATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "228e69d3-d4a8-46b3-b168-69fe5f0f2df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x10cc1b450>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add edge betwee reflect and generate.\n",
    "builder.add_edge(REFLECT, GENERATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0b064593-75ee-46e4-98f7-261471c3efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## This is conditional edge. Should continue method give feedback 6 times, then end it.\n",
    "\n",
    "def should_continue(state: List[BaseMessage]):\n",
    "    if len(state) > 3:\n",
    "        return END\n",
    "    return REFLECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b8cd8aaf-cf75-4cad-973e-a5a80c070f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x10cc1b450>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "builder.add_conditional_edges(GENERATE, should_continue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ca2b38eb-5c95-4b60-a3a0-080bbc895864",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "26f50cce-2680-48a2-af6f-064399e5f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = HumanMessage(content=\"\"\"Make this tweet better:\"\n",
    "                                    @LangChainAI\n",
    "            ‚Äî newly Tool Calling feature is seriously underrated.\n",
    "\n",
    "            After a long wait, it's  here- making the implementation of agents across different models with function calling - super easy.\n",
    "\n",
    "            Made a video covering their newest blog post\n",
    "\n",
    "                                  \"\"\")\n",
    "response = graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2097ccb1-06c7-4d2f-8bfe-da5e172e0d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Make this tweet better:\"\\n                                    @LangChainAI\\n            ‚Äî newly Tool Calling feature is seriously underrated.\\n\\n            After a long wait, it\\'s  here- making the implementation of agents across different models with function calling - super easy.\\n\\n            Made a video covering their newest blog post\\n\\n                                  ', additional_kwargs={}, response_metadata={}, id='611a1c5e-08e8-4664-a1ba-3ec3fea53a93'),\n",
       " AIMessage(content=\"üöÄ LangChain's new Tool Calling feature is a game-changer! ü§©  Implementing agents across different models with function calling just got WAY easier.  Check out my video breakdown of their latest blog post! #LangChain #AI #ToolCalling #Agents  [Link to Video]\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e61ca62c-6610-4122-89de-4d636a37c075-0', usage_metadata={'input_tokens': 109, 'output_tokens': 59, 'total_tokens': 168, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content='**Critique:**\\n\\n* **Original Length:**  A bit lengthy and could lose readers\\' attention.\\n* **Clarity:** While you explain the feature\\'s benefit, the language is slightly technical (\"implementation of agents across different models\").  A broader audience might miss the \"why should I care?\"\\n* **Excitement:**  The original lacks enthusiasm.  It states facts but doesn\\'t convey the impact or coolness of the feature.\\n* **Call to Action:**  No clear call to action (watching your video).\\n* **Hashtags:**  No hashtags to increase discoverability.\\n\\n\\n**Recommendations:**\\n\\n* **Brevity:** I\\'ve shortened the tweet significantly to capture attention quickly.  Ideal tweet length is under 280 characters, but aim for even shorter if possible for maximum impact.\\n* **Enthusiasm:** Using emojis (üöÄ ü§©) and stronger language (\"game-changer,\" \"WAY easier\") injects personality and excitement.\\n* **Clarity and Relevance:** Focusing on the ease of use (\"just got WAY easier\") makes the benefit immediately clear.\\n* **Call to Action:**  Explicitly telling people to \"Check out my video\" encourages engagement.\\n* **Hashtags:** Added relevant hashtags like #LangChain, #AI, #ToolCalling, and #Agents to boost visibility and reach a wider audience interested in these topics.\\n* **Link to Video:**  Crucially, include a direct link to your video! This makes it effortless for people to follow through.\\n\\n**Additional Tips for Virality:**\\n\\n* **Consider a Visual:** Adding a compelling thumbnail image or short GIF related to your video can significantly increase engagement.\\n* **Engage with Replies:**  Respond to comments and questions on your tweet to foster a sense of community and keep the conversation going.\\n* **Tag LangChain:** Consider tagging @LangChainAI in your tweet (as you did originally).  They might retweet it, exposing your content to a much larger audience.\\n* **Run a Poll:**  Ask your followers a related question about their experiences with LangChain or agent implementation to spark discussion.\\n* **Best Times to Tweet:**  Research the optimal times to tweet for your target audience to maximize visibility.  Tools like SproutSocial or Buffer can help with this.\\n', additional_kwargs={}, response_metadata={}, id='64e05d55-0e47-43b6-afed-b3f582185349'),\n",
       " AIMessage(content=\"üöÄ LangChain's new Tool Calling is a GAME CHANGER! Building AI agents just got WAY easier! ü§© Check out my video explaining how: [Link to Video] #LangChain #AI #ToolCalling #Agents @LangChainAI\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-7704f994-5e6b-4b14-b4b1-083e7b9a3a4f-0', usage_metadata={'input_tokens': 642, 'output_tokens': 50, 'total_tokens': 692, 'input_token_details': {'cache_read': 0}})]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0267c07e-cfce-476b-a99f-4f27901cc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = HumanMessage(content=\"\"\"Make this tweet better:\"\n",
    "                                   LLM came up with beam of data and solution. Langchaion is carrier to the LLM solution.\n",
    "\n",
    "                                  \"\"\")\n",
    "response = graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8d85a771-813c-4c8b-bf20-b70512282895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Make this tweet better:\"\\n                                   LLM came up with beam of data and solution. Langchaion is carrier to the LLM solution.\\n\\n                                  ', additional_kwargs={}, response_metadata={}, id='50ecb742-887e-474e-b0f9-869207dfba4a'),\n",
       " AIMessage(content='LangChain ü§ù LLMs:  Think of LLMs as the powerhouse generating brilliant insights, and LangChain as the delivery system, bringing those solutions straight to your applications. #LangChain #LLMs #AI #Data\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-af385083-b5be-4799-92f1-842c44f51950-0', usage_metadata={'input_tokens': 78, 'output_tokens': 46, 'total_tokens': 124, 'input_token_details': {'cache_read': 0}}),\n",
       " HumanMessage(content='**Critique:**\\n\\n* **Jargon:** The original tweet uses terms like \"beam of data\" which, while evocative, might not be universally understood.  It assumes a level of familiarity with LLM outputs that a broader audience might not possess.\\n* **Clarity:** The relationship between the LLM and LangChain isn\\'t immediately clear.  It reads as though they are separate entities working independently rather than in concert.\\n* **Lack of Engagement:** The original tweet is a statement, not a conversation starter.  It lacks elements that encourage interaction, such as questions, strong opinions, or calls to action.\\n* **Missing Hashtags:** Hashtags are crucial for discoverability on Twitter.\\n\\n**Recommendations:**\\n\\n* **Simplify the Language:** Replace technical jargon with more accessible terms.  Focus on the *benefit* of using LangChain with LLMs.\\n* **Clarify the Relationship:**  Use an analogy or metaphor to clearly illustrate how LangChain and LLMs work together. The revised tweet uses the \"powerhouse/delivery system\" analogy.\\n* **Add a Call to Action (Optional):** Consider adding a question like \"What are you building with LangChain?\" or a link to relevant resources.\\n* **Use Relevant Hashtags:** Include hashtags like #LangChain, #LLMs, #AI, and #Data to increase visibility.\\n* **Keep it Concise:**  Tweets perform best when they are short and punchy. The revised tweet is well within Twitter\\'s character limit, leaving room for users to add their own comments when retweeting.\\n* **Consider Adding Visuals:**  A simple image or GIF related to LLMs or data could further boost engagement.\\n\\n**Further Suggestions for Virality:**\\n\\n* **Engage with Replies:** Respond to comments and questions to foster a sense of community.\\n* **Run Polls:**  Ask your followers about their experiences with LLMs or LangChain.\\n* **Share Use Cases:**  Showcase interesting projects built with LangChain to inspire others.\\n* **Use Humor (If Appropriate):**  A well-placed emoji or a touch of humor can make your tweets more relatable.\\n\\n\\nBy implementing these changes, you can transform a dry, technical tweet into an engaging and informative message that resonates with a wider audience and sparks conversation.\\n', additional_kwargs={}, response_metadata={}, id='1cb4993f-8348-4ffb-b5cb-39d7b191cbe5'),\n",
       " AIMessage(content='Unleash the power of LLMs! üöÄ LangChain makes it easy to integrate these intelligent powerhouses into your own apps.  Think of it as the bridge between brilliant insights and real-world solutions.  #LangChain #LLMs #AI #DataScience #ArtificialIntelligence What are *you* building?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-57366804-a87f-4b2d-8075-97b014fac895-0', usage_metadata={'input_tokens': 599, 'output_tokens': 65, 'total_tokens': 664, 'input_token_details': {'cache_read': 0}})]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755672f3-92f8-48ef-ad55-befd0b218065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-env-reflection",
   "language": "python",
   "name": "poetry-env-reflection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
