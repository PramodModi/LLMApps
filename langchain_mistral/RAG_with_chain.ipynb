{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f15cdf-a67a-48a4-995f-873f262aa182",
   "metadata": {},
   "source": [
    "## End to End flow\n",
    "### Load text, slpit text, store embedded text into vector database, query to vector database, pass context and question to llm, parse result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfc7a02-b2c9-47d2-b644-3a2b244bcdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "mistral_api_key = os.environ[\"MISTRAL_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a74b4e-9ddc-4489-a607-b6ae8c08d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "chatModel = ChatMistralAI(\n",
    "    mistral_api_key=mistral_api_key,\n",
    "    model=\"mistral-large-latest\",\n",
    "    temperature=1,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d2025e-a34f-4d52-8d90-d0b2451ad33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa12b11-7352-480d-8f68-df8f82380821",
   "metadata": {},
   "source": [
    "## Load and chunk document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81fa9c9-c8c6-4959-ba76-51aea81ae043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "loaded_document = TextLoader('./data/state_of_the_union.txt').load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "chunks_of_text = text_splitter.split_documents(loaded_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1b8f0-ed42-48eb-a6f0-d9f5917410d0",
   "metadata": {},
   "source": [
    "### Use FAISS Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3155310-89dd-491f-b8e9-8a8ea703f4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pramodmodi/Library/Caches/pypoetry/virtualenvs/langchain-mistral-xuCIEomg-py3.11/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "vector_db = FAISS.from_documents(chunks_of_text, \n",
    "                                 embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"),\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a6850f-d8e6-4e07-89ba-7407c3051f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849473a6-c44b-4079-a1f3-1bdbc77bc050",
   "metadata": {},
   "source": [
    "### Use chain to pass context and question to llm and then parse result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03541b0-d08b-4a78-a8ba-c39001c05a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chatModel\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain.invoke(\"what did he say about ketanji brown jackson?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba351ec-fb75-4b84-ac95-0b49fce544a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He said that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court, and described her as \"one of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c3457-a04f-4fd5-9c5e-1e5ec43e80e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-env-mistral",
   "language": "python",
   "name": "poetry-env-mistral"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
