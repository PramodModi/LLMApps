{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723fc5c7-c94f-4e32-b963-92410c917ac6",
   "metadata": {},
   "source": [
    "### Reflexion\n",
    "Do the research on a given topic. Collect data from LLM -> Give self feedback -> Get online search query from data -> Collect data from online search -> get result of combined data -> do the evaluation -> again get data from tool (online) and repeat the process and finallly give output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d607e-394c-4482-9f9e-2d7a8bc0a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b608152-5736-4307-98b7-15b3b09d525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3cb35-0de9-419f-a55e-762369b65371",
   "metadata": {},
   "source": [
    "## Schema\n",
    "* Reflection class is a critique and having reflection schema\n",
    "* AnswerQuestion class has schema of answer, which includes reflection as one of the field\n",
    "* ReviseAnser is the revisor, derived from AnswerQuestion. Having reference as field which will consist citation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a47ce96-2a0d-4718-b299-8554cb4a562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reflection(BaseModel):\n",
    "    \"\"\"reflection on the initial answer\"\"\"\n",
    "    missing: str = Field(description=\"Critique of what is missing.\")\n",
    "    superfluous: str = Field(description=\"Critique of what is superfluous\")\n",
    "\n",
    "\n",
    "class AnswerQuestion(BaseModel):\n",
    "    \"\"\"Answer the question.\"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"~250 word detailed answer to the question.\")\n",
    "    missing: str = Field(description=\"Critique of what is missing.\")\n",
    "    superfluous: str = Field(description=\"Critique of what is superfluous\")\n",
    "    search_queries: List[str] = Field(\n",
    "        description=\"1-3 search queries for researching improvements to address the critique of your current answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Forcing citation in the model encourages grounded responses\n",
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"\"\"Revise your original answer to your question.\"\"\"\n",
    "\n",
    "    references: List[str] = Field(\n",
    "        description=\"Citations motivating your updated answer.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b8b2cb-2868-4c9e-a5f1-0fc70b08afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_tools import (\n",
    "    PydanticToolsParser,\n",
    "    JsonOutputToolsParser,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4a045-a486-4ef2-a5d5-291f95c7273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "google_api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
    "tavily_api_key = os.environ[\"TAVILY_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb079a7-00f1-4bd5-83ae-bdc82d903242",
   "metadata": {},
   "source": [
    "## Gemini-1.5-pro LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907eb40a-bbea-41cb-a0b0-9a3090b9f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9be0d1-fb1e-4878-b1af-523ad4158a86",
   "metadata": {},
   "source": [
    "## First Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee647c38-fbba-4584-a1f3-7b5797126f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are expert researcher.\n",
    "                Current time: {time}\n",
    "                1. {first_instruction}\n",
    "                2. Reflect and critique your answer. Be severe to maximize improvement.\n",
    "                3. Recommend search queries to research information and improve your answer.\"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        #(\"system\", \"Answer the user's question above using the required format.\"),\n",
    "    ]\n",
    ").partial(\n",
    "    time=lambda: datetime.datetime.now().isoformat(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111de2c5-cc42-4bb4-8f63-97aeee96970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_responder = actor_prompt_template.partial(\n",
    "    first_instruction=\"Provide a detailed ~250 word answer.\"\n",
    ") | llm.bind_tools(tools=[AnswerQuestion], tool_choice=\"AnswerQuestion\")\n",
    "validator = PydanticToolsParser(tools=[AnswerQuestion])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b9a86-eb1f-4a94-b13f-f748f277504d",
   "metadata": {},
   "source": [
    "## Second Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a4853-dad5-403e-8b5a-4802818f452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_instructions = \"\"\"Revise your previous answer using the new information.\n",
    "    - You should use the previous critique to add important information to your answer.\n",
    "        - You MUST include numerical citations in your revised answer to ensure it can be verified.\n",
    "        - Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of:\n",
    "            - [1] https://example.com\n",
    "            - [2] https://example.com\n",
    "    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7519b75d-4a34-4521-a241-960650de627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisor node\n",
    "revisor = actor_prompt_template.partial(\n",
    "    first_instruction=revise_instructions\n",
    ") | llm.bind_tools(tools=[ReviseAnswer], tool_choice=\"ReviseAnswer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac98c7-55d9-4901-9d4c-c68f3899754d",
   "metadata": {},
   "source": [
    "## Online search with Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611725c-b452-47f0-8917-cd80e68f8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tavily Search\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_tool = [TavilySearchResults(tavily_api_key = tavily_api_key, max_results=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55222990-b6b5-4f2d-83c8-979b27aa90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation, ToolExecutor\n",
    "tool_executor = ToolExecutor(tavily_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92822733-adc9-4389-9436-065c1d72ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chains import parser\n",
    "from langchain_core.messages import AIMessage, BaseMessage, ToolMessage, HumanMessage, SystemMessage\n",
    "\n",
    "## Node for online search \n",
    "def execute_tools(state: List[BaseMessage]) -> List[BaseMessage]:\n",
    "    # Take last tool from state\n",
    "    tool_invocation: AIMessage = state[-1]\n",
    "\n",
    "    # Invoke tool\n",
    "    parsed_tool_calls = parser.invoke(tool_invocation)\n",
    "\n",
    "    # Parse the output and get search queries and ids\n",
    "    ids = []\n",
    "    tool_invocations = []\n",
    "    for parsed_call in parsed_tool_calls:\n",
    "        for query in parsed_call[\"args\"][\"search_queries\"]:\n",
    "            tool_invocations.append(\n",
    "                ToolInvocation(\n",
    "                    tool=\"tavily_search_results_json\",\n",
    "                    tool_input=query,\n",
    "                )\n",
    "            )\n",
    "            ids.append(parsed_call[\"id\"])\n",
    "\n",
    "\n",
    "    # execute the search tool.\n",
    "    outputs = tool_executor.batch(tool_invocations)\n",
    "\n",
    "    # now map the output with id (as a key) with query and output\n",
    "    outputs_map = defaultdict(dict)\n",
    "    for id_, invocation, output in zip(ids, tool_invocations, outputs):\n",
    "        outputs_map[id_][invocation.tool_input] = output\n",
    "\n",
    "    tool_messages = []\n",
    "    for id_, query_outputs in outputs_map.items():\n",
    "        tool_messages.append(\n",
    "            ToolMessage(content=json.dumps(query_outputs), tool_call_id=id_)\n",
    "        )\n",
    "\n",
    "    return tool_messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e87f6-1527-487e-97d5-dd13b859dce5",
   "metadata": {},
   "source": [
    "## Create the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f18dc-8a70-4219-8d8b-10bf82114a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "MAX_ITERATIONS = 2\n",
    "builder = MessageGraph()\n",
    "\n",
    "## Add nodes\n",
    "builder.add_node(\"draft\", first_responder)\n",
    "builder.add_node(\"execute_tools\", execute_tools)\n",
    "builder.add_node(\"revise\", revisor)\n",
    "\n",
    "## Add edges. \n",
    "## Draft output will have research as well as crtique/feedback. Then it will go to online search.\n",
    "## Online search result wil go to revise. Based on revise prompt llm will revise the content and reference.\n",
    "builder.add_edge(\"draft\", \"execute_tools\")\n",
    "builder.add_edge(\"execute_tools\", \"revise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0245d5c5-f18e-4f9f-8767-c4f314c075d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add conditional edge.\n",
    "## Revisor will send for revision to execution tool by MAX_ITERATIONS times.\n",
    "\n",
    "def event_loop(state: List[BaseMessage]) -> str:\n",
    "    # AIMessage will keep adding in state on every execution of node.\n",
    "    # Before first call of this method, there are two AIMessage already there by earlier node execution.\n",
    "    count_tool_visits = sum(isinstance(item, AIMessage) for item in state)\n",
    "    #print(\"count_tool_visits = \", count_tool_visits)\n",
    "    if count_tool_visits -2 > MAX_ITERATIONS:\n",
    "        return END\n",
    "    return \"execute_tools\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df26e83c-6a3f-4feb-8110-bbc148c28f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_conditional_edges(\"revise\", event_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e706ca9-e669-41f8-a475-09ee6b7d8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set entry point and build the graph\n",
    "builder.set_entry_point(\"draft\")\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49152e78-c5d4-4973-87ee-aadf93d292f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute the graph\n",
    "\n",
    "res = graph.invoke(\n",
    "    [\"Write about Agentic AI and real life use cases, list startups that do that and raised capital.\"]\n",
    ")\n",
    "print(res[-1].tool_calls[0][\"args\"][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00c9e8-3dd4-4192-8ede-73a9dba5003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"References = \", res[-1].tool_calls[0][\"args\"][\"references\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d9a64-b83b-4257-970e-cc0e60dd5608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-env-reflexion",
   "language": "python",
   "name": "poetry-env-reflexion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
